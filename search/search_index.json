{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Pipeline Editor Pipeline Editor is a web app that allows the users to build and run Machine Learning pipelines using drag and drop without having to set up development environment. Video See the Pipeline Editor in action Cloud Pipelines - Build machine learning pipelines without writing code App Try the Pipeline Editor now. No registration required. App features Build pipelines using drag and drop Execute pipelines in the cloud Submit pipelines to Google Cloud Vertex Pipelines with a single click. Start building right away No registration required You own your data Components Time-proven component format A library of preloaded components Fast-growing public component ecosystem Add your own components (public or private) Easy to create your own components Components can be written in any language (Python, Shell, R, Java, C#, etc). Compatible with Kubeflow Pipelines components ( component.yaml files) Find components on GitHub: Ark-kun/pipeline_components , kubeflow/pipelines/components and hundreds more. Pipelines Create, save, import and export Submit for execution with a single click Additional information Report bugs and request features Contact Privacy policy","title":"Pipeline Editor"},{"location":"#pipeline-editor","text":"Pipeline Editor is a web app that allows the users to build and run Machine Learning pipelines using drag and drop without having to set up development environment.","title":"Pipeline Editor"},{"location":"#video","text":"See the Pipeline Editor in action Cloud Pipelines - Build machine learning pipelines without writing code","title":"Video"},{"location":"#app","text":"Try the Pipeline Editor now. No registration required.","title":"App"},{"location":"#app-features","text":"Build pipelines using drag and drop Execute pipelines in the cloud Submit pipelines to Google Cloud Vertex Pipelines with a single click. Start building right away No registration required You own your data Components Time-proven component format A library of preloaded components Fast-growing public component ecosystem Add your own components (public or private) Easy to create your own components Components can be written in any language (Python, Shell, R, Java, C#, etc). Compatible with Kubeflow Pipelines components ( component.yaml files) Find components on GitHub: Ark-kun/pipeline_components , kubeflow/pipelines/components and hundreds more. Pipelines Create, save, import and export Submit for execution with a single click","title":"App features"},{"location":"#additional-information","text":"Report bugs and request features Contact Privacy policy","title":"Additional information"},{"location":"privacy_policy/","text":"Privacy policy This Privacy Policy describes how we collect and process your personal information in relation to Cloud Pipelines' Pipeline Editor application (\"the Application\"). Information we collect Types of data and how they are processed. User content The Application allows the User to create or import user content (pipelines and components). The Application is client-side and does not currently use any remote storage for any of the components and pipelines created or imported by the user. All user content is currently only stored on user's machine in the user's web browser local storage. As such, the user data is not shared with the owners of the Application. However, if instructed by the user, the user content can be sent to a third-party service specified by the User. See the sections below for the detailed information. Search queries The Application has a search feature. When the user submits a search query, the query is sent to the service performing teh search. Web request metadata The Application might make HTTP requests to various web services on user behalf. The information and metadata contained in these requests (IP addresses, HTTP headers etc) is processed by the requested web services. Services where the Application may send user data Cloud providers Google Cloud The Application allows the user to authenticate with Google Cloud using their Google Cloud account. During the authentication, the information which user provides to Google is processed by Google. If instructed by the user, the Application can send a compiled pipeline to Google Cloud API to be executed in the user's Google Cloud project, explicitly specified by the user. The information that the user provides to Google is subject to Google's Privacy Policy. Google Privacy Policy Google Cloud Privacy Policy GitHub Component and pipeline library The Application is configured with the default set of components and pipelines. These components and pipelines are stored on GitHub. The Application downloads these components and pipelines from GitHub on user's behalf. Search The Application allows the user to search for components on GitHub. When performing the search, the search query is provided to GitHub for processing. The information about the types of data collected by GitHub and the way this data is processed can be found in GitHub's Privacy Policy Authentication with third-party services The Application allows the users to authenticate with third-party services. In this case, the Application will be able to access some Data, stored by these third-party services, for the purpose of authentication, storing user components and pipelines and sending user pipelines for execution. Some of the services listed below may also collect Personal Data for targeting and profiling purposes; to find out more, please refer to the description of each service. Google OAuth (Google LLC) Google OAuth is a registration and authentication service provided by Google LLC and is connected to the Google network. Personal Data processed: various types of Data as specified in the privacy policy of the service. Privacy Policy Analytics The services contained in this section enable the Owner to monitor and analyze web traffic and can be used to keep track of User behavior. Google Analytics (Google LLC) Google Analytics is a web analysis service provided by Google LLC (\u201cGoogle\u201d). Google utilizes the Data collected to track and examine the use of the Application, to prepare reports on its activities and share them with other Google services. Google may use the Data collected to contextualize and personalize the ads of its own advertising network. Privacy Policy Opt Out Hosting and backend infrastructure GitHub The Application uses GitHub and GitHub Pages for hosting infrastructure. The information about the types of data collected by GitHub and the way this data is processed can be found in GitHub's Privacy Policy Additional information about Data collection and processing Changes to this privacy policy The Owner reserves the right to make changes to this privacy policy at any time by notifying its Users on this page and possibly within the Application. It is strongly recommended to check this page often, referring to the date of the last modification listed at the bottom. Latest update: January 23, 2022","title":"Privacy policy"},{"location":"privacy_policy/#privacy-policy","text":"This Privacy Policy describes how we collect and process your personal information in relation to Cloud Pipelines' Pipeline Editor application (\"the Application\").","title":"Privacy policy"},{"location":"privacy_policy/#information-we-collect","text":"Types of data and how they are processed.","title":"Information we collect"},{"location":"privacy_policy/#user-content","text":"The Application allows the User to create or import user content (pipelines and components). The Application is client-side and does not currently use any remote storage for any of the components and pipelines created or imported by the user. All user content is currently only stored on user's machine in the user's web browser local storage. As such, the user data is not shared with the owners of the Application. However, if instructed by the user, the user content can be sent to a third-party service specified by the User. See the sections below for the detailed information.","title":"User content"},{"location":"privacy_policy/#search-queries","text":"The Application has a search feature. When the user submits a search query, the query is sent to the service performing teh search.","title":"Search queries"},{"location":"privacy_policy/#web-request-metadata","text":"The Application might make HTTP requests to various web services on user behalf. The information and metadata contained in these requests (IP addresses, HTTP headers etc) is processed by the requested web services.","title":"Web request metadata"},{"location":"privacy_policy/#services-where-the-application-may-send-user-data","text":"","title":"Services where the Application may send user data"},{"location":"privacy_policy/#cloud-providers","text":"","title":"Cloud providers"},{"location":"privacy_policy/#google-cloud","text":"The Application allows the user to authenticate with Google Cloud using their Google Cloud account. During the authentication, the information which user provides to Google is processed by Google. If instructed by the user, the Application can send a compiled pipeline to Google Cloud API to be executed in the user's Google Cloud project, explicitly specified by the user. The information that the user provides to Google is subject to Google's Privacy Policy. Google Privacy Policy Google Cloud Privacy Policy","title":"Google Cloud"},{"location":"privacy_policy/#github","text":"","title":"GitHub"},{"location":"privacy_policy/#component-and-pipeline-library","text":"The Application is configured with the default set of components and pipelines. These components and pipelines are stored on GitHub. The Application downloads these components and pipelines from GitHub on user's behalf.","title":"Component and pipeline library"},{"location":"privacy_policy/#search","text":"The Application allows the user to search for components on GitHub. When performing the search, the search query is provided to GitHub for processing. The information about the types of data collected by GitHub and the way this data is processed can be found in GitHub's Privacy Policy","title":"Search"},{"location":"privacy_policy/#authentication-with-third-party-services","text":"The Application allows the users to authenticate with third-party services. In this case, the Application will be able to access some Data, stored by these third-party services, for the purpose of authentication, storing user components and pipelines and sending user pipelines for execution. Some of the services listed below may also collect Personal Data for targeting and profiling purposes; to find out more, please refer to the description of each service.","title":"Authentication with third-party services"},{"location":"privacy_policy/#google-oauth-google-llc","text":"Google OAuth is a registration and authentication service provided by Google LLC and is connected to the Google network. Personal Data processed: various types of Data as specified in the privacy policy of the service. Privacy Policy","title":"Google OAuth (Google LLC)"},{"location":"privacy_policy/#analytics","text":"The services contained in this section enable the Owner to monitor and analyze web traffic and can be used to keep track of User behavior.","title":"Analytics"},{"location":"privacy_policy/#google-analytics-google-llc","text":"Google Analytics is a web analysis service provided by Google LLC (\u201cGoogle\u201d). Google utilizes the Data collected to track and examine the use of the Application, to prepare reports on its activities and share them with other Google services. Google may use the Data collected to contextualize and personalize the ads of its own advertising network. Privacy Policy Opt Out","title":"Google Analytics (Google LLC)"},{"location":"privacy_policy/#hosting-and-backend-infrastructure","text":"","title":"Hosting and backend infrastructure"},{"location":"privacy_policy/#github_1","text":"The Application uses GitHub and GitHub Pages for hosting infrastructure. The information about the types of data collected by GitHub and the way this data is processed can be found in GitHub's Privacy Policy","title":"GitHub"},{"location":"privacy_policy/#additional-information-about-data-collection-and-processing","text":"","title":"Additional information about Data collection and processing"},{"location":"privacy_policy/#changes-to-this-privacy-policy","text":"The Owner reserves the right to make changes to this privacy policy at any time by notifying its Users on this page and possibly within the Application. It is strongly recommended to check this page often, referring to the date of the last modification listed at the bottom. Latest update: January 23, 2022","title":"Changes to this privacy policy"},{"location":"components/create_component_from_python_function/","text":"Create a component from a Python function What is a pipeline component? A pipeline consists of component tasks connected together in a graph. Components have inputs and outputs. Component reads the input data, processes it and outputs the results. Output of one component can be passed to another component's input. That's how components are connected together to form a pipeline. Each component has an interface (input and output definitions), an implementation (usually a containerized command-line program) and metadata (component name, description and other optional properties). The components are saved in ComponentSpec format files ( component.yaml ) that can be shared anywhere on the Internet. When building a pipeline, several components can be loaded from component.yaml files and connected together to form a pipeline. Container components are based on containerized command-line programs. But that does not mean that creating a component always involves building new container images or writing command-line programs. There is a way to automatically generate a component from a Python function without a need to build any container images. Creating a component from a Python function Creating a component from a Python function is very easy (1 line of code). (However the function needs to follow several simple rules.) Do not forget to install the Cloud Pipelines SDK : pip install cloud-pipelines . Simple example Let's start with an example. This is a simple python function: def add(a: int, b: int) -> int: return a + b It's a normal Python function. There is nothing in this function that is specific to Cloud Pipelines. However this function can be converted to a pipeline component using the pipelines.components.create_component_from_func function from the Cloud Pipelines SDK : from pipelines.components import create_component_from_func add_op = create_component_from_func( func=add, output_component_file=\"component.yaml\", ) Reading and writing files. Let's look at a more complex example. This function filters a text file by searching for a certain string pattern and returns only the matching lines. def filter_text( text_path: InputPath(), filtered_text_path: OutputPath(), pattern: str, ): import re with open(text_path, 'r') as reader: with open(filtered_text_path, 'w') as writer: for line in reader: if re.search(pattern, line): writer.write(line) # Creating a component filter_text_op = create_component_from_func( func=filter_text, output_component_file=\"component.yaml\", ) This function reads the data from a file ( text_path ) and writes the data to a file ( filtered_text_path ). Such path parameters need to be annotated using the InputPath() and OutputPath() annotations. Also note that the import statement is placed inside the function. This is needed so that the component function is self-contained. The InputPath and OutputPath annotations The text_path: InputPath() annotation tells the system that the input data for the text input should be placed into some file and the path of that file should be given to the function as a value for the text_path function parameter. The filtered_text_path: OutputPath() annotation tells the system that it should generate and give the function a path (via the filtered_text_path parameter) where the function should write the output data. After the function finishes the execution, the system will take the output data written by the function, put it into storage and make it available for passing to other components. Why do we need the InputPath parameter annotation? Not all data can be passed/received as a simple string. Examples: binary data, large data, directories. In all these cases, the code should read data from a file or directory pointed to by a path. This is why we have a text_path: InputPath() parameter and not text: str parameter (although the latter could still work for short texts). Another reason why the InputPath annotation is needed is that the component function code is executed inside a hermetic container. The text file needs to somehow be placed inside the container. Only the system can do that. The text_path: InputPath() annotation tells the system that the input data for the text input should be placed into some file and the path of that file should be given to the function as a value for the text_path function parameter. Similarly the filtered_text_path: OutputPath() parameter annotation is needed so that the system knows that it needs to get the output data out of the container when the function finishes its execution. Default parameter values The create_component_from_func function supports functions with default parameter values. This results in the generated component inputs becoming optional. Path parameters annotated with InputPath() can have a default value of None which makes those file inputs optional. The default parameter values can use any Python built-in type. (Only the built-in types can be used because the function needs to remain self-contained). def some_func( some_int: int = 3, some_path: InputPath() = None, ): from pathlib import Path if some_path: Path(some_path).read_text() ... Mapping function parameters to inputs and outputs The function parameters (the parameter names and type annotations) are mapped to component inputs and outputs in a certain way. This example demonstrates all aspects of the mapping def my_func( # Directly supported types: # Mapped to input with name \"some_string\" and type \"String\" some_string: str, # Mapped to input with name \"some_string\" and type \"Integer\" some_integer: int, # Mapped to input with name \"some_float\" and type \"Float\" some_float: float, # Mapped to input with name \"some_boolean\" and type \"Boolean\" some_boolean: bool, # Mapped to input with name \"some_list\" and type \"JsonArray\" some_list: list, # Mapped to input with name \"some_dict\" and type \"JsonObject\" some_dict: dict, # Mapped to input with name \"any_thing\" and no type (compatible with any type. Will receive a string value at runtime!) any_thing, # Other types # Mapped to input with name \"some_uri\" and type \"Uri\" (Will receive a string value at runtime!) some_uri: \"Uri\", # Mapped to input with name \"some_uri\" and type \"BigInt\" (Will receive a string value at runtime!) some_uri: BigInt, # Paths: # Mapped to input with name \"input1\" (the \"_path\" suffix is removed) input1_path: InputPath(\"\"), # Mapped to output with name \"output1\" and type \"CSV\" (the \"_path\" suffix is removed) output1_path: OutputPath(\"CSV\"), ) -> typing.NamedTuple(\"Outputs\", [ # Mapped to output with name \"output_string\" and type \"String\" (\"output_string\", str), # Mapped to output with name \"output_uri\" and type \"Uri\" (function needs to return a string) (\"output_uri\", \"Uri\"), ]): ... return (\"Some string\", \"some-uri://...\") Supported types The create_component_from_func function supports functions with any type annotations (including arbitrary type name annotations). However only a few basic Python types are handled in a special way where the SDK supports automatic data serialization and deserialization. The full list of directly supported basic Python types is: str , int , float , bool , list , dict . Plus the special annotations for input and output paths: InputPath(...) and OutputPath(...) . All other types can still be used, but they are not automatically deserialized, so the Python component function code receives the parameter values as strings. For example, with the param1: BigInt or param1: \"BigInt\" parameter type annotation, the function will receive a plain str object. Advanced component configuration Python packages A Python component can dynamically install Python packages before running the component function. To specify the packages, use the packages_to_install parameter of the create_component_from_func function: create_component_from_func(..., packages_to_install=[\"pandas==1.14.0\"]) . Each item follows the pip install syntax. Base container image All container components are executed inside a Docker container. By default the official python container image is used. To explicitly specify the container image, use the base_image parameter of the create_component_from_func function: create_component_from_func(..., base_image=\"tensorflow/tensorflow:2.8\") . Choose a container image that has all or most of the Python packages that you need, to reduce the startup time and the number of packages that need to be dynamically installed using packages_to_install . filter_text_op = create_component_from_func( func=filter_text, output_component_file=\"component.yaml\", base_image=\"tensorflow/tensorflow:2.8\", packages_to_install=[\"pandas==1.14.0\"], ) Rules The function must be standalone (self-contained) The function source code is copied to the generated component. Any code outside of the function definition will be left out. So the function must be self-contained. The function should import all modules inside the function body. The function can only call functions and use classes from the imported modules. For example, the component function cannot call a sibling function. Fortunately, in Python any code can be placed inside a function: imports, other functions, classes: def my_func(): import helper_module def inner_func(): ... class InnerClass: ... helper_module.foo() inner_func() obj = InnerClass() Component guidelines Components should be \"pure\" The output of a component should only depend on the input values passed to the component. Avoid reading/changing mutable external global state Such components are not pure and have complicated interdependencies and race condition issues that the system cannot know about. As an example, avoid components like this: Change object in some external system Delete object in some external system A Create object in some external system component is OK as long as the resulting object is immutable (does not change in the future). Component name should start with a verb Components are function, operations, transformations. Component names are easier to understand when they start with a verb instead of being a noun. Example: train_model instead of trainer .","title":"Create a component from a Python function"},{"location":"components/create_component_from_python_function/#create-a-component-from-a-python-function","text":"","title":"Create a component from a Python function"},{"location":"components/create_component_from_python_function/#what-is-a-pipeline-component","text":"A pipeline consists of component tasks connected together in a graph. Components have inputs and outputs. Component reads the input data, processes it and outputs the results. Output of one component can be passed to another component's input. That's how components are connected together to form a pipeline. Each component has an interface (input and output definitions), an implementation (usually a containerized command-line program) and metadata (component name, description and other optional properties). The components are saved in ComponentSpec format files ( component.yaml ) that can be shared anywhere on the Internet. When building a pipeline, several components can be loaded from component.yaml files and connected together to form a pipeline. Container components are based on containerized command-line programs. But that does not mean that creating a component always involves building new container images or writing command-line programs. There is a way to automatically generate a component from a Python function without a need to build any container images.","title":"What is a pipeline component?"},{"location":"components/create_component_from_python_function/#creating-a-component-from-a-python-function","text":"Creating a component from a Python function is very easy (1 line of code). (However the function needs to follow several simple rules.) Do not forget to install the Cloud Pipelines SDK : pip install cloud-pipelines .","title":"Creating a component from a Python function"},{"location":"components/create_component_from_python_function/#simple-example","text":"Let's start with an example. This is a simple python function: def add(a: int, b: int) -> int: return a + b It's a normal Python function. There is nothing in this function that is specific to Cloud Pipelines. However this function can be converted to a pipeline component using the pipelines.components.create_component_from_func function from the Cloud Pipelines SDK : from pipelines.components import create_component_from_func add_op = create_component_from_func( func=add, output_component_file=\"component.yaml\", )","title":"Simple example"},{"location":"components/create_component_from_python_function/#reading-and-writing-files","text":"Let's look at a more complex example. This function filters a text file by searching for a certain string pattern and returns only the matching lines. def filter_text( text_path: InputPath(), filtered_text_path: OutputPath(), pattern: str, ): import re with open(text_path, 'r') as reader: with open(filtered_text_path, 'w') as writer: for line in reader: if re.search(pattern, line): writer.write(line) # Creating a component filter_text_op = create_component_from_func( func=filter_text, output_component_file=\"component.yaml\", ) This function reads the data from a file ( text_path ) and writes the data to a file ( filtered_text_path ). Such path parameters need to be annotated using the InputPath() and OutputPath() annotations. Also note that the import statement is placed inside the function. This is needed so that the component function is self-contained.","title":"Reading and writing files."},{"location":"components/create_component_from_python_function/#the-inputpath-and-outputpath-annotations","text":"The text_path: InputPath() annotation tells the system that the input data for the text input should be placed into some file and the path of that file should be given to the function as a value for the text_path function parameter. The filtered_text_path: OutputPath() annotation tells the system that it should generate and give the function a path (via the filtered_text_path parameter) where the function should write the output data. After the function finishes the execution, the system will take the output data written by the function, put it into storage and make it available for passing to other components.","title":"The InputPath and OutputPath annotations"},{"location":"components/create_component_from_python_function/#why-do-we-need-the-inputpath-parameter-annotation","text":"Not all data can be passed/received as a simple string. Examples: binary data, large data, directories. In all these cases, the code should read data from a file or directory pointed to by a path. This is why we have a text_path: InputPath() parameter and not text: str parameter (although the latter could still work for short texts). Another reason why the InputPath annotation is needed is that the component function code is executed inside a hermetic container. The text file needs to somehow be placed inside the container. Only the system can do that. The text_path: InputPath() annotation tells the system that the input data for the text input should be placed into some file and the path of that file should be given to the function as a value for the text_path function parameter. Similarly the filtered_text_path: OutputPath() parameter annotation is needed so that the system knows that it needs to get the output data out of the container when the function finishes its execution.","title":"Why do we need the InputPath parameter annotation?"},{"location":"components/create_component_from_python_function/#default-parameter-values","text":"The create_component_from_func function supports functions with default parameter values. This results in the generated component inputs becoming optional. Path parameters annotated with InputPath() can have a default value of None which makes those file inputs optional. The default parameter values can use any Python built-in type. (Only the built-in types can be used because the function needs to remain self-contained). def some_func( some_int: int = 3, some_path: InputPath() = None, ): from pathlib import Path if some_path: Path(some_path).read_text() ...","title":"Default parameter values"},{"location":"components/create_component_from_python_function/#mapping-function-parameters-to-inputs-and-outputs","text":"The function parameters (the parameter names and type annotations) are mapped to component inputs and outputs in a certain way. This example demonstrates all aspects of the mapping def my_func( # Directly supported types: # Mapped to input with name \"some_string\" and type \"String\" some_string: str, # Mapped to input with name \"some_string\" and type \"Integer\" some_integer: int, # Mapped to input with name \"some_float\" and type \"Float\" some_float: float, # Mapped to input with name \"some_boolean\" and type \"Boolean\" some_boolean: bool, # Mapped to input with name \"some_list\" and type \"JsonArray\" some_list: list, # Mapped to input with name \"some_dict\" and type \"JsonObject\" some_dict: dict, # Mapped to input with name \"any_thing\" and no type (compatible with any type. Will receive a string value at runtime!) any_thing, # Other types # Mapped to input with name \"some_uri\" and type \"Uri\" (Will receive a string value at runtime!) some_uri: \"Uri\", # Mapped to input with name \"some_uri\" and type \"BigInt\" (Will receive a string value at runtime!) some_uri: BigInt, # Paths: # Mapped to input with name \"input1\" (the \"_path\" suffix is removed) input1_path: InputPath(\"\"), # Mapped to output with name \"output1\" and type \"CSV\" (the \"_path\" suffix is removed) output1_path: OutputPath(\"CSV\"), ) -> typing.NamedTuple(\"Outputs\", [ # Mapped to output with name \"output_string\" and type \"String\" (\"output_string\", str), # Mapped to output with name \"output_uri\" and type \"Uri\" (function needs to return a string) (\"output_uri\", \"Uri\"), ]): ... return (\"Some string\", \"some-uri://...\")","title":"Mapping function parameters to inputs and outputs"},{"location":"components/create_component_from_python_function/#supported-types","text":"The create_component_from_func function supports functions with any type annotations (including arbitrary type name annotations). However only a few basic Python types are handled in a special way where the SDK supports automatic data serialization and deserialization. The full list of directly supported basic Python types is: str , int , float , bool , list , dict . Plus the special annotations for input and output paths: InputPath(...) and OutputPath(...) . All other types can still be used, but they are not automatically deserialized, so the Python component function code receives the parameter values as strings. For example, with the param1: BigInt or param1: \"BigInt\" parameter type annotation, the function will receive a plain str object.","title":"Supported types"},{"location":"components/create_component_from_python_function/#advanced-component-configuration","text":"","title":"Advanced component configuration"},{"location":"components/create_component_from_python_function/#python-packages","text":"A Python component can dynamically install Python packages before running the component function. To specify the packages, use the packages_to_install parameter of the create_component_from_func function: create_component_from_func(..., packages_to_install=[\"pandas==1.14.0\"]) . Each item follows the pip install syntax.","title":"Python packages"},{"location":"components/create_component_from_python_function/#base-container-image","text":"All container components are executed inside a Docker container. By default the official python container image is used. To explicitly specify the container image, use the base_image parameter of the create_component_from_func function: create_component_from_func(..., base_image=\"tensorflow/tensorflow:2.8\") . Choose a container image that has all or most of the Python packages that you need, to reduce the startup time and the number of packages that need to be dynamically installed using packages_to_install . filter_text_op = create_component_from_func( func=filter_text, output_component_file=\"component.yaml\", base_image=\"tensorflow/tensorflow:2.8\", packages_to_install=[\"pandas==1.14.0\"], )","title":"Base container image"},{"location":"components/create_component_from_python_function/#rules","text":"","title":"Rules"},{"location":"components/create_component_from_python_function/#the-function-must-be-standalone-self-contained","text":"The function source code is copied to the generated component. Any code outside of the function definition will be left out. So the function must be self-contained. The function should import all modules inside the function body. The function can only call functions and use classes from the imported modules. For example, the component function cannot call a sibling function. Fortunately, in Python any code can be placed inside a function: imports, other functions, classes: def my_func(): import helper_module def inner_func(): ... class InnerClass: ... helper_module.foo() inner_func() obj = InnerClass()","title":"The function must be standalone (self-contained)"},{"location":"components/create_component_from_python_function/#component-guidelines","text":"","title":"Component guidelines"},{"location":"components/create_component_from_python_function/#components-should-be-pure","text":"The output of a component should only depend on the input values passed to the component.","title":"Components should be \"pure\""},{"location":"components/create_component_from_python_function/#avoid-readingchanging-mutable-external-global-state","text":"Such components are not pure and have complicated interdependencies and race condition issues that the system cannot know about. As an example, avoid components like this: Change object in some external system Delete object in some external system A Create object in some external system component is OK as long as the resulting object is immutable (does not change in the future).","title":"Avoid reading/changing mutable external global state"},{"location":"components/create_component_from_python_function/#component-name-should-start-with-a-verb","text":"Components are function, operations, transformations. Component names are easier to understand when they start with a verb instead of being a noun. Example: train_model instead of trainer .","title":"Component name should start with a verb"}]}